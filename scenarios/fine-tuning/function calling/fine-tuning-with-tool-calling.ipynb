{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5faef6ec",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397bfd7c",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5ad7986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: azure-identity in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (1.23.0)\n",
      "Requirement already satisfied: openai in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (1.92.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (1.34.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (45.0.4)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (4.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: pycparser in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests azure-identity openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ceb4f",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "781499b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subscription = \"6a6fff00-4464-4eab-a6b1-0b533c7202e0\"\n",
    "resource_group = \"rg-jialiuai\"\n",
    "resource_name = \"jialiu-aoai-ncus\"\n",
    "api_version = \"2025-04-01-preview\"\n",
    "\n",
    "base_model = \"gpt-4.1-mini\"\n",
    "\n",
    "model_deployment_name = \"gpt-4.1-mini-stock-hallucination\"\n",
    "\n",
    "train_data_file = \"Data/stock-train-hallucination_tools.jsonl\"\n",
    "test_data_file = \"Data/stock-test-hallucination_query_format.jsonl\"\n",
    "eval_data_file_template = \"Data/stock-eval-hallucination_{model}_query_format.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8a340",
   "metadata": {},
   "source": [
    "### Init Azure OpenAI Client\n",
    "\n",
    "It will use token authentication. Please make sure to run `az login` in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44098a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential,\n",
    "    \"https://cognitiveservices.azure.com/.default\",\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=f\"https://{resource_name}.openai.azure.com/\",\n",
    "    api_version=api_version,\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd52db",
   "metadata": {},
   "source": [
    "## Prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9203b66",
   "metadata": {},
   "source": [
    "### Preview training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2401606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 96\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. If you can't find the exact stock ticker symbol, you can ask for clarification. \"}\n",
      "{'role': 'user', 'content': \"What was the highest price that Bank of America's stock reached last month?\"}\n",
      "{'role': 'assistant', 'tool_calls': [{'id': 'call_333605', 'type': 'function', 'function': {'name': 'get_last_nday_stock_price', 'arguments': '{\"symbol\": \"BAC\", \"period\": \"1mo\"}'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Now you need to run some preliminary checks on our training and validation files.\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming the current directory is the root of your repository\n",
    "with Path(train_data_file).open(\"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6a99c",
   "metadata": {},
   "source": [
    "### Upload data to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91c7747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-c359ba8517e748afbcc9bfde84bbec67\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Upload the training dataset files to Azure OpenAI with the SDK.\n",
    "with Path(train_data_file).open(\"rb\") as file:\n",
    "    training_response = client.files.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca89af",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc03c3",
   "metadata": {},
   "source": [
    "### Submit finetuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86cac4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-HnXTdssdEhCp9ANlaseHXZkh\n",
      "Status: validating_files\n",
      "{\n",
      "  \"id\": \"ftjob-HnXTdssdEhCp9ANlaseHXZkh\",\n",
      "  \"created_at\": 1756163279,\n",
      "  \"error\": {\n",
      "    \"code\": null,\n",
      "    \"message\": null,\n",
      "    \"param\": null\n",
      "  },\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\",\n",
      "    \"n_epochs\": \"auto\"\n",
      "  },\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": \"org-hTGGKhbVgQIQFEXlrcWgLHk9\",\n",
      "  \"result_files\": [],\n",
      "  \"seed\": 721143020,\n",
      "  \"status\": \"validating_files\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-QAfKMt8EoewWC17cPD4nM7\",\n",
      "  \"validation_file\": null,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": [],\n",
      "  \"metadata\": null,\n",
      "  \"method\": {\n",
      "    \"type\": \"supervised\",\n",
      "    \"dpo\": null,\n",
      "    \"reinforcement\": null,\n",
      "    \"supervised\": {\n",
      "      \"hyperparameters\": {\n",
      "        \"batch_size\": \"auto\",\n",
      "        \"learning_rate_multiplier\": \"auto\",\n",
      "        \"n_epochs\": \"auto\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"user_provided_suffix\": null,\n",
      "  \"usage_metrics\": null,\n",
      "  \"shared_with_openai\": false,\n",
      "  \"eval_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=base_model,  # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5458db4",
   "metadata": {},
   "source": [
    "### Track training job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f13c071f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# If the job isn't done yet, poll it every 10 seconds.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfailed\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     response = client.fine_tuning.jobs.retrieve(job_id)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response.model_dump_json(indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\n",
    "        \"Elapsed time: {} minutes {} seconds\".format(\n",
    "            int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)\n",
    "        )\n",
    "    )\n",
    "    status = response.status\n",
    "    print(f\"Status: {status}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f\"Fine-tuning job {job_id} finished with status: {status}\")\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print(\"Checking other fine-tune jobs for this resource.\")\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f\"Found {len(response.data)} fine-tune jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb78d5a",
   "metadata": {},
   "source": [
    "### Retrieve finetuned model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "725ee7c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'notFound', 'message': 'The specified entity cannot be found.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Retrieve fine_tuned_model name\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfine_tuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.model_dump_json(indent=\u001b[32m2\u001b[39m))\n\u001b[32m      6\u001b[39m fine_tuned_model = response.fine_tuned_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/resources/fine_tuning/jobs/jobs.py:207\u001b[39m, in \u001b[36mJobs.retrieve\u001b[39m\u001b[34m(self, fine_tuning_job_id, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fine_tuning_job_id:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `fine_tuning_job_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tuning_job_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/fine_tuning/jobs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfine_tuning_job_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1195\u001b[39m, in \u001b[36mSyncAPIClient.get\u001b[39m\u001b[34m(self, path, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1192\u001b[39m opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m, url=path, **options)\n\u001b[32m   1193\u001b[39m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[32m   1194\u001b[39m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'code': 'notFound', 'message': 'The specified entity cannot be found.'}}"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe311cd7",
   "metadata": {},
   "source": [
    "## Deploy fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n",
      "Created\n",
      "{'id': '/subscriptions/6a6fff00-4464-4eab-a6b1-0b533c7202e0/resourceGroups/rg-jialiuai/providers/Microsoft.CognitiveServices/accounts/jialiu-aoai-ncus/deployments/gpt-4.1-mini-stock-hallucination', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-4.1-mini-stock-hallucination', 'sku': {'name': 'standard', 'capacity': 50}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-4.1-mini-2025-04-14.ft-dcd2c319f0e441a5a5a04f9c2090ecaa', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'currentCapacity': 50, 'capabilities': {'chatCompletion': 'true', 'area': 'US', 'responses': 'true', 'assistants': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 60, 'count': 50}, {'key': 'token', 'renewalPeriod': 60, 'count': 50000}]}, 'systemData': {'createdBy': 'daweil@microsoft.com', 'createdByType': 'User', 'createdAt': '2025-08-25T20:44:51.4079816Z', 'lastModifiedBy': 'daweil@microsoft.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2025-08-25T20:44:51.4079816Z'}, 'etag': '\"46334b3f-bb54-480c-88dc-bea37a78bf5e\"'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "deploy_params = {\"api-version\": \"2025-04-01-preview\"}\n",
    "deploy_headers = {\n",
    "    \"Authorization\": f\"Bearer {token.token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"GlobalStandard\", \"capacity\": 50},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model,  # retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "\n",
    "print(\"Creating a new deployment...\")\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372f153",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51774d",
   "metadata": {},
   "source": [
    "### Model to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f538e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_compare = [\n",
    "    \"gpt-4.1\",\n",
    "    \"gpt-4.1-mini\",\n",
    "    model_deployment_name,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27d3b5",
   "metadata": {},
   "source": [
    "### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d2d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Replace 'Data/stock-test-token-reduction.jsonl' with the actual path to your file\n",
    "test_file_path = Path(test_data_file)\n",
    "\n",
    "with test_file_path.open(errors=\"ignore\") as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefc7af",
   "metadata": {},
   "source": [
    "### Prepare Prompt for Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93ab0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Don't make assumptions about what values to plug into functions. If you can't find the exact stock ticker symbol, you can ask for clarification. \"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_stock_price\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {},\n",
    "          \"required\": [\n",
    "            \"symbol\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_last_nday_stock_price\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {},\n",
    "          \"required\": [\n",
    "            \"symbol\",\n",
    "            \"period\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b2508",
   "metadata": {},
   "source": [
    "### Batch inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa230e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on model gpt-4.1\n",
      "starting on 0\n",
      "starting on 1\n",
      "starting on 2\n",
      "starting on 3\n",
      "starting on 4\n",
      "starting on 5\n",
      "starting on 6\n",
      "starting on 7\n",
      "starting on 8\n",
      "starting on 9\n",
      "starting on model gpt-4.1-mini\n",
      "starting on 0\n",
      "starting on 1\n",
      "starting on 2\n",
      "starting on 3\n",
      "starting on 4\n",
      "starting on 5\n",
      "starting on 6\n",
      "starting on 7\n",
      "starting on 8\n",
      "starting on 9\n",
      "starting on model gpt-4.1-mini-stock-hallucination\n",
      "starting on 0\n",
      "starting on 1\n",
      "starting on 2\n",
      "starting on 3\n",
      "starting on 4\n",
      "starting on 5\n",
      "starting on 6\n",
      "starting on 7\n",
      "starting on 8\n",
      "starting on 9\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for model in models_to_compare:\n",
    "    print(f\"starting on model {model}\")\n",
    "\n",
    "    eval_file_path = Path(eval_data_file_template.format(model=model))\n",
    "    with eval_file_path.open(\"w\", encoding=\"utf-8\") as output_file:\n",
    "        for i, json_str in enumerate(json_list):\n",
    "            row = json.loads(json_str)\n",
    "            result = {\n",
    "                \"item\": {\n",
    "                    **row[\"item\"],\n",
    "                }\n",
    "            }\n",
    "            print(f\"starting on {i}\")\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": row[\"item\"][\"query\"],\n",
    "                    },\n",
    "                ],\n",
    "                temperature=0.0,  # to reduce randomness\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\",\n",
    "            )\n",
    "            tool_calls = completion.choices[0].message.tool_calls\n",
    "            if tool_calls:\n",
    "                result[\"item\"][\"actual_tool_calls\"] = [tool_calls[0].model_dump()]\n",
    "            else:\n",
    "                result[\"item\"][\"actual_tool_calls\"] = []\n",
    "\n",
    "            output_file.write(json.dumps(result) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767876d",
   "metadata": {},
   "source": [
    "### Prepare Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f19155e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for model gpt-4.1 with file ID: file-6303980bb96b4a6fac0b31a76b3da71d\n",
      "Evaluation for model gpt-4.1-mini with file ID: file-e16b4c2eed6d4008a5118a464fbd6251\n",
      "Evaluation for model gpt-4.1-mini-stock-hallucination with file ID: file-43e79c5e1ab04705a1b97f8f46316b29\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "eval_file_mapping = {}\n",
    "\n",
    "# Upload the training dataset files to Azure OpenAI with the SDK.\n",
    "for model in models_to_compare:\n",
    "    with Path(eval_data_file_template.format(model=model)).open(\"rb\") as file:\n",
    "        eval_response = client.files.create(file=file, purpose=\"evals\")\n",
    "\n",
    "    eval_file_id = eval_response.id\n",
    "    eval_file_mapping[model] = eval_file_id\n",
    "\n",
    "    print(f\"Evaluation for model {model} with file ID: {eval_file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6111",
   "metadata": {},
   "source": [
    "### Define python grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7a846425",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_grader = \"\"\"\n",
    "def grade(sample, item) -> float:\n",
    "    actual_tool_calls = item['actual_tool_calls']\n",
    "    expected_tool_calls = item['expected_tool_calls']\n",
    "    return grade_tool_calls(actual_tool_calls, expected_tool_calls)\n",
    "\n",
    "def grade_tool_calls(actual_tool_calls, expected_tool_calls):\n",
    "    # Case 1: Both are empty (None or empty list)\n",
    "    if (not actual_tool_calls) and (not expected_tool_calls):\n",
    "        return 10.0\n",
    "\n",
    "    # Case 2: One is empty, one is not\n",
    "    if (not actual_tool_calls) != (not expected_tool_calls):\n",
    "        return 0.0\n",
    "\n",
    "    # Case 3: Both are not empty - check if function objects are equal\n",
    "    if actual_tool_calls and expected_tool_calls:\n",
    "        return compare_function_calls(actual_tool_calls, expected_tool_calls)\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def compare_function_calls(actual_calls, expected_calls):\n",
    "    if len(actual_calls) != len(expected_calls):\n",
    "        return 1.0\n",
    "\n",
    "    for actual, expected in zip(actual_calls, expected_calls):\n",
    "        # Compare function name and arguments, ignore call ID\n",
    "        actual_func = actual.get(\"function\", {})\n",
    "        expected_func = expected.get(\"function\", {})\n",
    "\n",
    "        # Compare function name\n",
    "        if actual_func.get(\"name\") != expected_func.get(\"name\"):\n",
    "            return 2.0\n",
    "\n",
    "        # Compare function arguments (parse JSON strings if needed)\n",
    "        actual_args = actual_func.get(\"arguments\", \"{}\")\n",
    "        expected_args = expected_func.get(\"arguments\", \"{}\")\n",
    "\n",
    "        try:\n",
    "            actual_args_dict = json.loads(actual_args) if isinstance(actual_args, str) else actual_args\n",
    "            expected_args_dict = json.loads(expected_args) if isinstance(expected_args, str) else expected_args\n",
    "\n",
    "            if actual_args_dict != expected_args_dict:\n",
    "                return 3.0\n",
    "        except json.JSONDecodeError:\n",
    "            # If we can't parse, do string comparison\n",
    "            if actual_args != expected_args:\n",
    "                return 4.0\n",
    "\n",
    "    return 10.0\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d5344",
   "metadata": {},
   "source": [
    "### Create Stock Hallucination Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8837c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_eval = client.evals.create(\n",
    "    name=\"Stock Hallucination Eval\",\n",
    "    data_source_config={\n",
    "        \"type\": \"custom\",\n",
    "        \"item_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\"},\n",
    "                \"actual_tool_calls\": {\"type\": \"array\"},\n",
    "                \"expected_tool_calls\": {\"type\": \"array\"},\n",
    "            },\n",
    "            \"required\": [\"query\", \"actual_tool_calls\", \"expected_tool_calls\"],\n",
    "        },\n",
    "    },\n",
    "    testing_criteria=[\n",
    "        {\n",
    "            \"type\": \"python\",\n",
    "            \"name\": \"Tool Use Evaluator\",\n",
    "            \"source\": python_grader,\n",
    "            \"pass_threshold\": 9.9,\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881aefb2",
   "metadata": {},
   "source": [
    "### Define data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "83f7a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_to_compare:\n",
    "    data_source = {\n",
    "        \"type\": \"jsonl\",\n",
    "        \"source\": {\"type\": \"file_id\", \"id\": eval_file_mapping[model]},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f084d",
   "metadata": {},
   "source": [
    "### Create sampling runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3ef52fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_41_completions_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1\",\n",
    "    eval_id=stock_eval.id,\n",
    "    data_source=data_source,\n",
    ")\n",
    "gpt_41_mini_completions_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1-mini\",\n",
    "    eval_id=stock_eval.id,\n",
    "    data_source=data_source,\n",
    ")\n",
    "gpt_41_mini_ft_completions_run = client.evals.runs.create(\n",
    "    name=model_deployment_name,\n",
    "    eval_id=stock_eval.id,\n",
    "    data_source=data_source,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "28db3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalrun_68ad1ce5231c8191b1fc3cb3ccf5cf1f queued ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce601fc81919648ff8911ff8a60 queued ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce69ca081919d0ee0ca58495228 queued ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce5231c8191b1fc3cb3ccf5cf1f in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce601fc81919648ff8911ff8a60 in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce69ca081919d0ee0ca58495228 in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce5231c8191b1fc3cb3ccf5cf1f completed ResultCounts(errored=0, failed=5, passed=5, total=10)\n",
      "evalrun_68ad1ce601fc81919648ff8911ff8a60 in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce69ca081919d0ee0ca58495228 in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad1ce5231c8191b1fc3cb3ccf5cf1f completed ResultCounts(errored=0, failed=5, passed=5, total=10)\n",
      "evalrun_68ad1ce601fc81919648ff8911ff8a60 completed ResultCounts(errored=0, failed=5, passed=5, total=10)\n",
      "evalrun_68ad1ce69ca081919d0ee0ca58495228 completed ResultCounts(errored=0, failed=5, passed=5, total=10)\n"
     ]
    }
   ],
   "source": [
    "def poll_runs(eval_id, run_ids):\n",
    "    # poll both runs at the same time, until they are complete or failed\n",
    "    while True:\n",
    "        runs = [client.evals.runs.retrieve(run_id, eval_id=eval_id) for run_id in run_ids]\n",
    "        for run in runs:\n",
    "            print(run.id, run.status, run.result_counts)\n",
    "        if all(run.status in (\"completed\", \"failed\") for run in runs):\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "poll_runs(\n",
    "    stock_eval.id,\n",
    "    [\n",
    "        gpt_41_completions_run.id,\n",
    "        gpt_41_mini_completions_run.id,\n",
    "        gpt_41_mini_ft_completions_run.id,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663fe7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
