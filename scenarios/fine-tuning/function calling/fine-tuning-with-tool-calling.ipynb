{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5faef6ec",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397bfd7c",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ad7986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting azure-identity\n",
      "  Downloading azure_identity-1.24.0-py3-none-any.whl.metadata (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai\n",
      "  Downloading openai-1.101.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting azure-core>=1.31.0 (from azure-identity)\n",
      "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cryptography>=2.5 (from azure-identity)\n",
      "  Downloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity)\n",
      "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from azure-identity)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/daweil/azureai-samples-fork/.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Collecting cffi>=1.14 (from cryptography>=2.5->azure-identity)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=2.5->azure-identity)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.24.0-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.9/187.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.101.0-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.8/810.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.2/107.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, sniffio, PyJWT, pycparser, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, httpcore, cffi, anyio, pydantic, httpx, cryptography, azure-core, openai, msal, msal-extensions, azure-identity\n",
      "Successfully installed PyJWT-2.10.1 annotated-types-0.7.0 anyio-4.10.0 azure-core-1.35.0 azure-identity-1.24.0 certifi-2025.8.3 cffi-1.17.1 charset_normalizer-3.4.3 cryptography-45.0.6 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 msal-1.33.0 msal-extensions-1.3.1 openai-1.101.0 pycparser-2.22 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.5 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests azure-identity openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ceb4f",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781499b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subscription = \"6a6fff00-4464-4eab-a6b1-0b533c7202e0\"\n",
    "resource_group = \"rg-jialiuai\"\n",
    "resource_name = \"jialiu-aoai-ncus\"\n",
    "api_version = \"2025-04-01-preview\"\n",
    "\n",
    "base_model = \"gpt-4.1-mini\"\n",
    "\n",
    "model_deployment_name = \"gpt-4.1-mini-stock-hallucination\"\n",
    "\n",
    "train_data_file = \"Data/stock-train-hallucination_tools.jsonl\"\n",
    "test_data_file = \"Data/stock-test-hallucination_query_format.jsonl\"\n",
    "eval_data_file_template = \"Data/stock-eval-hallucination_{model}_query_format.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8a340",
   "metadata": {},
   "source": [
    "### Init Azure OpenAI Client\n",
    "\n",
    "It will use token authentication. Please make sure to run `az login` in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44098a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential,\n",
    "    \"https://cognitiveservices.azure.com/.default\",\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=f\"https://{resource_name}.openai.azure.com/\",\n",
    "    api_version=api_version,\n",
    "    azure_ad_token_provider=token_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd52db",
   "metadata": {},
   "source": [
    "## Prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9203b66",
   "metadata": {},
   "source": [
    "### Preview training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2401606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 96\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. If you can't find the exact stock ticker symbol, you can ask for clarification. \"}\n",
      "{'role': 'user', 'content': \"What was the highest price that Bank of America's stock reached last month?\"}\n",
      "{'role': 'assistant', 'tool_calls': [{'id': 'call_333605', 'type': 'function', 'function': {'name': 'get_last_nday_stock_price', 'arguments': '{\"symbol\": \"BAC\", \"period\": \"1mo\"}'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Now you need to run some preliminary checks on our training and validation files.\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming the current directory is the root of your repository\n",
    "with Path(train_data_file).open(\"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6a99c",
   "metadata": {},
   "source": [
    "### Upload data to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91c7747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-c359ba8517e748afbcc9bfde84bbec67\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Upload the training dataset files to Azure OpenAI with the SDK.\n",
    "with Path(train_data_file).open(\"rb\") as file:\n",
    "    training_response = client.files.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca89af",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc03c3",
   "metadata": {},
   "source": [
    "### Submit finetuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86cac4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-HnXTdssdEhCp9ANlaseHXZkh\n",
      "Status: validating_files\n",
      "{\n",
      "  \"id\": \"ftjob-HnXTdssdEhCp9ANlaseHXZkh\",\n",
      "  \"created_at\": 1756163279,\n",
      "  \"error\": {\n",
      "    \"code\": null,\n",
      "    \"message\": null,\n",
      "    \"param\": null\n",
      "  },\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\",\n",
      "    \"n_epochs\": \"auto\"\n",
      "  },\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": \"org-hTGGKhbVgQIQFEXlrcWgLHk9\",\n",
      "  \"result_files\": [],\n",
      "  \"seed\": 721143020,\n",
      "  \"status\": \"validating_files\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-QAfKMt8EoewWC17cPD4nM7\",\n",
      "  \"validation_file\": null,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": [],\n",
      "  \"metadata\": null,\n",
      "  \"method\": {\n",
      "    \"type\": \"supervised\",\n",
      "    \"dpo\": null,\n",
      "    \"reinforcement\": null,\n",
      "    \"supervised\": {\n",
      "      \"hyperparameters\": {\n",
      "        \"batch_size\": \"auto\",\n",
      "        \"learning_rate_multiplier\": \"auto\",\n",
      "        \"n_epochs\": \"auto\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"user_provided_suffix\": null,\n",
      "  \"usage_metrics\": null,\n",
      "  \"shared_with_openai\": false,\n",
      "  \"eval_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=base_model,  # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5458db4",
   "metadata": {},
   "source": [
    "### Track training job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f13c071f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# If the job isn't done yet, poll it every 10 seconds.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfailed\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     response = client.fine_tuning.jobs.retrieve(job_id)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response.model_dump_json(indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\n",
    "        \"Elapsed time: {} minutes {} seconds\".format(\n",
    "            int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)\n",
    "        )\n",
    "    )\n",
    "    status = response.status\n",
    "    print(f\"Status: {status}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f\"Fine-tuning job {job_id} finished with status: {status}\")\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print(\"Checking other fine-tune jobs for this resource.\")\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f\"Found {len(response.data)} fine-tune jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb78d5a",
   "metadata": {},
   "source": [
    "### Retrieve finetuned model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ee7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe311cd7",
   "metadata": {},
   "source": [
    "## Deploy fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n",
      "Created\n",
      "{'id': '/subscriptions/6a6fff00-4464-4eab-a6b1-0b533c7202e0/resourceGroups/rg-jialiuai/providers/Microsoft.CognitiveServices/accounts/jialiu-aoai-ncus/deployments/gpt-4.1-mini-stock-hallucination', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-4.1-mini-stock-hallucination', 'sku': {'name': 'standard', 'capacity': 50}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-4.1-mini-2025-04-14.ft-dcd2c319f0e441a5a5a04f9c2090ecaa', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'currentCapacity': 50, 'capabilities': {'chatCompletion': 'true', 'area': 'US', 'responses': 'true', 'assistants': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 60, 'count': 50}, {'key': 'token', 'renewalPeriod': 60, 'count': 50000}]}, 'systemData': {'createdBy': 'daweil@microsoft.com', 'createdByType': 'User', 'createdAt': '2025-08-25T20:44:51.4079816Z', 'lastModifiedBy': 'daweil@microsoft.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2025-08-25T20:44:51.4079816Z'}, 'etag': '\"46334b3f-bb54-480c-88dc-bea37a78bf5e\"'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "token = credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "deploy_params = {\"api-version\": \"2025-04-01-preview\"}\n",
    "deploy_headers = {\n",
    "    \"Authorization\": f\"Bearer {token.token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"GlobalStandard\", \"capacity\": 50},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model,  # retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "\n",
    "print(\"Creating a new deployment...\")\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372f153",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51774d",
   "metadata": {},
   "source": [
    "### Model to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_compare = [\n",
    "    \"gpt-4.1\",\n",
    "    \"gpt-4.1-mini\",\n",
    "    model_deployment_name,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27d3b5",
   "metadata": {},
   "source": [
    "### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2d6c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Replace 'Data/stock-test-token-reduction.jsonl' with the actual path to your file\n",
    "test_file_path = Path(test_data_file)\n",
    "\n",
    "with test_file_path.open(errors=\"ignore\") as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefc7af",
   "metadata": {},
   "source": [
    "### Prepare Prompt for Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93ab0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Don't make assumptions about what values to plug into functions. If you can't find the exact stock ticker symbol, you can ask for clarification. \"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_stock_price\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {},\n",
    "          \"required\": [\n",
    "            \"symbol\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_last_nday_stock_price\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {},\n",
    "          \"required\": [\n",
    "            \"symbol\",\n",
    "            \"period\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b2508",
   "metadata": {},
   "source": [
    "### Batch inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa230e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on model gpt-4.1\n",
      "starting on 0\n",
      "None\n",
      "starting on 1\n",
      "None\n",
      "starting on 2\n",
      "None\n",
      "starting on 3\n",
      "None\n",
      "starting on 4\n",
      "None\n",
      "starting on 5\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_jP4GajXp19u1v2Z5Z1XUSnSr', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on 6\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_reXSx7i88c7MinR0Y8HwaJbY', function=Function(arguments='{}', name='get_current_stock_price'), type='function')]\n",
      "starting on 7\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_JsB4Vho1046GmEBFvbjeHTIR', function=Function(arguments='{}', name='get_current_stock_price'), type='function')]\n",
      "starting on 8\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_huVcmZn5U5csP9370EyKs2g3', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on 9\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_WgJSgiBY4OI76IVXJ0c54O0G', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on model gpt-4.1-mini\n",
      "starting on 0\n",
      "None\n",
      "starting on 1\n",
      "None\n",
      "starting on 2\n",
      "None\n",
      "starting on 3\n",
      "None\n",
      "starting on 4\n",
      "None\n",
      "starting on 5\n",
      "None\n",
      "starting on 6\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_ltI1Hy8uWUCnHpM0C0EEle8P', function=Function(arguments='{}', name='get_current_stock_price'), type='function')]\n",
      "starting on 7\n",
      "None\n",
      "starting on 8\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_Srls6UQf9JnYAlxkGZRMSBBI', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on 9\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_tnVWYJZFSaR20gfS3TM9198L', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on model gpt-4-1-mini-2025-04-14-ft-hallucination\n",
      "starting on 0\n",
      "None\n",
      "starting on 1\n",
      "None\n",
      "starting on 2\n",
      "None\n",
      "starting on 3\n",
      "None\n",
      "starting on 4\n",
      "None\n",
      "starting on 5\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_iWdQptBCsSdEuopZvphmM2d4', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on 6\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_535YqiuXZCTcmBQc3aQqlVOh', function=Function(arguments='{}', name='get_current_stock_price'), type='function')]\n",
      "starting on 7\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_qY60q8m3uQ6iYfReUHELgWJp', function=Function(arguments='{}', name='get_current_stock_price'), type='function')]\n",
      "starting on 8\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_EnwdPNJLlHs16q8nL18w1RJ1', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n",
      "starting on 9\n",
      "[ChatCompletionMessageFunctionToolCall(id='call_mD2vAAWXVopV9HiWHxOZubwm', function=Function(arguments='{}', name='get_last_nday_stock_price'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "for model in models_to_compare:\n",
    "    print(f\"starting on model {model}\")\n",
    "\n",
    "    eval_file_path = Path(eval_data_file_template.format(model=model))\n",
    "    with eval_file_path.open(\"w\", encoding=\"utf-8\") as output_file:\n",
    "        for i, json_str in enumerate(json_list):\n",
    "            row = json.loads(json_str)\n",
    "            result = {\n",
    "                \"item\": {\n",
    "                    **row[\"item\"],\n",
    "                }\n",
    "            }\n",
    "            print(f\"starting on {i}\")\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": system_prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": row[\"item\"][\"query\"],\n",
    "                    },\n",
    "                ],\n",
    "                temperature=0.0,  # to reduce randomness\n",
    "                tools=tools,\n",
    "            )\n",
    "            tool_calls = completion.choices[0].message.tool_calls\n",
    "            print(tool_calls)\n",
    "            if tool_calls:\n",
    "                result[\"item\"][\"actual_tool_calls\"] = [tool_calls[0].model_dump()]\n",
    "            else:\n",
    "                result[\"item\"][\"actual_tool_calls\"] = []\n",
    "\n",
    "            output_file.write(json.dumps(result) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767876d",
   "metadata": {},
   "source": [
    "### Prepare Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f19155e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for model gpt-4.1 with file ID: file-80cb58411ec744b7b7298a1621362c42\n",
      "Evaluation for model gpt-4.1-mini with file ID: file-bf23104a1d204dceb90f59d548768e36\n",
      "Evaluation for model gpt-4-1-mini-2025-04-14-ft-hallucination with file ID: file-10ee9a6f29ab4cd0a06b3caa655021c1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "eval_file_mapping = {}\n",
    "\n",
    "# Upload the training dataset files to Azure OpenAI with the SDK.\n",
    "for model in models_to_compare:\n",
    "    with Path(eval_data_file_template.format(model=model)).open(\"rb\") as file:\n",
    "        eval_response = client.files.create(file=file, purpose=\"evals\")\n",
    "\n",
    "    eval_file_id = eval_response.id\n",
    "    eval_file_mapping[model] = eval_file_id\n",
    "\n",
    "    print(f\"Evaluation for model {model} with file ID: {eval_file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6111",
   "metadata": {},
   "source": [
    "### Define python grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a846425",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_grader = \"\"\"\n",
    "def grade(sample, item) -> float:\n",
    "    actual_tool_calls = item['actual_tool_calls']\n",
    "    expected_tool_calls = item['expected_tool_calls']\n",
    "    return grade_tool_calls(actual_tool_calls, expected_tool_calls)\n",
    "\n",
    "def grade_tool_calls(actual_tool_calls, expected_tool_calls):\n",
    "    # Case 1: Both are empty (None or empty list)\n",
    "    if (not actual_tool_calls) and (not expected_tool_calls):\n",
    "        return 10.0\n",
    "\n",
    "    # Case 2: One is empty, one is not\n",
    "    if (not actual_tool_calls) != (not expected_tool_calls):\n",
    "        return 0.0\n",
    "\n",
    "    # Case 3: Both are not empty - check if function objects are equal\n",
    "    if actual_tool_calls and expected_tool_calls:\n",
    "        return compare_function_calls(actual_tool_calls, expected_tool_calls)\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def compare_function_calls(actual_calls, expected_calls):\n",
    "    if len(actual_calls) != len(expected_calls):\n",
    "        return 1.0\n",
    "\n",
    "    for actual, expected in zip(actual_calls, expected_calls):\n",
    "        # Compare function name and arguments, ignore call ID\n",
    "        actual_func = actual.get(\"function\", {})\n",
    "        expected_func = expected.get(\"function\", {})\n",
    "\n",
    "        # Compare function name\n",
    "        if actual_func.get(\"name\") != expected_func.get(\"name\"):\n",
    "            return 2.0\n",
    "\n",
    "        # Compare function arguments (parse JSON strings if needed)\n",
    "        # actual_args = actual_func.get(\"arguments\", \"{}\")\n",
    "        # expected_args = expected_func.get(\"arguments\", \"{}\")\n",
    "\n",
    "        # try:\n",
    "        #     actual_args_dict = json.loads(actual_args) if isinstance(actual_args, str) else actual_args\n",
    "        #     expected_args_dict = json.loads(expected_args) if isinstance(expected_args, str) else expected_args\n",
    "\n",
    "        #     if actual_args_dict != expected_args_dict:\n",
    "        #         return 3.0\n",
    "        # except json.JSONDecodeError:\n",
    "        #     # If we can't parse, do string comparison\n",
    "        #     if actual_args != expected_args:\n",
    "        #         return 4.0\n",
    "\n",
    "    return 10.0\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d5344",
   "metadata": {},
   "source": [
    "### Create Stock Hallucination Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8837c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_eval = client.evals.create(\n",
    "    name=\"Stock Hallucination Eval\",\n",
    "    data_source_config={\n",
    "        \"type\": \"custom\",\n",
    "        \"item_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\"},\n",
    "                \"actual_tool_calls\": {\"type\": \"array\"},\n",
    "                \"expected_tool_calls\": {\"type\": \"array\"},\n",
    "            },\n",
    "            \"required\": [\"query\", \"actual_tool_calls\", \"expected_tool_calls\"],\n",
    "        },\n",
    "    },\n",
    "    testing_criteria=[\n",
    "        {\n",
    "            \"type\": \"python\",\n",
    "            \"name\": \"Tool Use Evaluator\",\n",
    "            \"source\": python_grader,\n",
    "            \"pass_threshold\": 9.9,\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881aefb2",
   "metadata": {},
   "source": [
    "### Create sampling runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83f7a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_to_compare:\n",
    "    client.evals.runs.create(\n",
    "        name=model,\n",
    "        eval_id=stock_eval.id,\n",
    "        data_source={\n",
    "            \"type\": \"jsonl\",\n",
    "            \"source\": {\"type\": \"file_id\", \"id\": eval_file_mapping[model]},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28db3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalrun_68ad37ca77688191b42dcc916d9d22ca queued ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37c9d9e48191b7d5d68b2e0efa4c queued ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37c935a08191981615d7d119dca9 queued ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37ca77688191b42dcc916d9d22ca in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37c9d9e48191b7d5d68b2e0efa4c in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37c935a08191981615d7d119dca9 in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37ca77688191b42dcc916d9d22ca in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37c9d9e48191b7d5d68b2e0efa4c in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37c935a08191981615d7d119dca9 in_progress ResultCounts(errored=0, failed=0, passed=0, total=0)\n",
      "evalrun_68ad37ca77688191b42dcc916d9d22ca completed ResultCounts(errored=0, failed=0, passed=10, total=10)\n",
      "evalrun_68ad37c9d9e48191b7d5d68b2e0efa4c completed ResultCounts(errored=0, failed=2, passed=8, total=10)\n",
      "evalrun_68ad37c935a08191981615d7d119dca9 completed ResultCounts(errored=0, failed=0, passed=10, total=10)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def poll_runs(eval_id):\n",
    "    # poll both runs at the same time, until they are complete or failed\n",
    "    while True:\n",
    "        runs = client.evals.runs.list(eval_id=eval_id)\n",
    "        for run in runs:\n",
    "            print(run.id, run.status, run.result_counts)\n",
    "        if all(run.status in (\"completed\", \"failed\") for run in runs):\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "poll_runs(stock_eval.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663fe7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
