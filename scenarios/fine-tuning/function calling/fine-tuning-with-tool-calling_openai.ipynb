{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5faef6ec",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397bfd7c",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5ad7986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: azure-identity in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (1.23.0)\n",
      "Requirement already satisfied: openai in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (1.92.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (1.34.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (45.0.4)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-identity) (4.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: pycparser in /home/daweil/azureai-samples/.venv/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests azure-identity openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ceb4f",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781499b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"gpt-4.1-mini-2025-04-14\"\n",
    "\n",
    "train_data_file = \"Data/stock-train-hallucination_tools.jsonl\"\n",
    "eval_data_file = \"Data/stock-test-hallucination_query_format.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8a340",
   "metadata": {},
   "source": [
    "### Init OpenAI Client\n",
    "\n",
    "It will use token authentication. Please make sure to run `az login` in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44098a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd52db",
   "metadata": {},
   "source": [
    "## Prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9203b66",
   "metadata": {},
   "source": [
    "### Preview training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2401606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 96\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. If you can't find the exact stock ticker symbol, you can ask for clarification. \"}\n",
      "{'role': 'user', 'content': \"What was the highest price that Bank of America's stock reached last month?\"}\n",
      "{'role': 'assistant', 'tool_calls': [{'id': 'call_333605', 'type': 'function', 'function': {'name': 'get_last_nday_stock_price', 'arguments': '{\"symbol\": \"BAC\", \"period\": \"1mo\"}'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Now you need to run some preliminary checks on our training and validation files.\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming the current directory is the root of your repository\n",
    "with Path(train_data_file).open(\"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6a99c",
   "metadata": {},
   "source": [
    "### Upload data to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c7747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-DN7WK8S1SsfNQ4K9dcX6mQ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Upload the training dataset files to Azure OpenAI with the SDK.\n",
    "with Path(train_data_file).open(\"rb\") as file:\n",
    "    training_response = client.files.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca89af",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc03c3",
   "metadata": {},
   "source": [
    "### Submit finetuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86cac4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-kWszFvhCRHubbliaZPcUej4Q\n",
      "Status: validating_files\n",
      "{\n",
      "  \"id\": \"ftjob-kWszFvhCRHubbliaZPcUej4Q\",\n",
      "  \"created_at\": 1756165769,\n",
      "  \"error\": {\n",
      "    \"code\": null,\n",
      "    \"message\": null,\n",
      "    \"param\": null\n",
      "  },\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": \"auto\",\n",
      "    \"learning_rate_multiplier\": \"auto\",\n",
      "    \"n_epochs\": \"auto\"\n",
      "  },\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": \"org-hTGGKhbVgQIQFEXlrcWgLHk9\",\n",
      "  \"result_files\": [],\n",
      "  \"seed\": 258050106,\n",
      "  \"status\": \"validating_files\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-DN7WK8S1SsfNQ4K9dcX6mQ\",\n",
      "  \"validation_file\": null,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": [],\n",
      "  \"metadata\": null,\n",
      "  \"method\": {\n",
      "    \"type\": \"supervised\",\n",
      "    \"dpo\": null,\n",
      "    \"reinforcement\": null,\n",
      "    \"supervised\": {\n",
      "      \"hyperparameters\": {\n",
      "        \"batch_size\": \"auto\",\n",
      "        \"learning_rate_multiplier\": \"auto\",\n",
      "        \"n_epochs\": \"auto\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"user_provided_suffix\": null,\n",
      "  \"usage_metrics\": null,\n",
      "  \"shared_with_openai\": false,\n",
      "  \"eval_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=base_model,  # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5458db4",
   "metadata": {},
   "source": [
    "### Track training job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ftjob-kWszFvhCRHubbliaZPcUej4Q\",\n",
      "  \"created_at\": 1756165769,\n",
      "  \"error\": {\n",
      "    \"code\": null,\n",
      "    \"message\": null,\n",
      "    \"param\": null\n",
      "  },\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": 1756166715,\n",
      "  \"hyperparameters\": {\n",
      "    \"batch_size\": 1,\n",
      "    \"learning_rate_multiplier\": 2.0,\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": \"org-hTGGKhbVgQIQFEXlrcWgLHk9\",\n",
      "  \"result_files\": [],\n",
      "  \"seed\": 258050106,\n",
      "  \"status\": \"running\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-DN7WK8S1SsfNQ4K9dcX6mQ\",\n",
      "  \"validation_file\": null,\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": [],\n",
      "  \"metadata\": null,\n",
      "  \"method\": {\n",
      "    \"type\": \"supervised\",\n",
      "    \"dpo\": null,\n",
      "    \"reinforcement\": null,\n",
      "    \"supervised\": {\n",
      "      \"hyperparameters\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"learning_rate_multiplier\": 2.0,\n",
      "        \"n_epochs\": 3\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"user_provided_suffix\": null,\n",
      "  \"usage_metrics\": null,\n",
      "  \"shared_with_openai\": false,\n",
      "  \"eval_id\": null\n",
      "}\n",
      "Elapsed time: 33 minutes 50 seconds\n",
      "Status: running\n"
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\n",
    "        \"Elapsed time: {} minutes {} seconds\".format(\n",
    "            int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)\n",
    "        )\n",
    "    )\n",
    "    status = response.status\n",
    "    print(f\"Status: {status}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f\"Fine-tuning job {job_id} finished with status: {status}\")\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print(\"Checking other fine-tune jobs for this resource.\")\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f\"Found {len(response.data)} fine-tune jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb78d5a",
   "metadata": {},
   "source": [
    "### Retrieve finetuned model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ee7c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'notFound', 'message': 'The specified entity cannot be found.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Retrieve fine_tuned_model name\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfine_tuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.model_dump_json(indent=\u001b[32m2\u001b[39m))\n\u001b[32m      6\u001b[39m fine_tuned_model = response.fine_tuned_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/resources/fine_tuning/jobs/jobs.py:207\u001b[39m, in \u001b[36mJobs.retrieve\u001b[39m\u001b[34m(self, fine_tuning_job_id, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fine_tuning_job_id:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `fine_tuning_job_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tuning_job_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/fine_tuning/jobs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfine_tuning_job_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1195\u001b[39m, in \u001b[36mSyncAPIClient.get\u001b[39m\u001b[34m(self, path, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1192\u001b[39m opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m, url=path, **options)\n\u001b[32m   1193\u001b[39m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[32m   1194\u001b[39m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'code': 'notFound', 'message': 'The specified entity cannot be found.'}}"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "# job_id = \"ftjob-kWszFvhCRHubbliaZPcUej4Q\"\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372f153",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767876d",
   "metadata": {},
   "source": [
    "### Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f19155e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation file ID: file-916415237d2d47daa74270298cd4446c\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Upload the training dataset files to Azure OpenAI with the SDK.\n",
    "with Path(eval_data_file).open(\"rb\") as file:\n",
    "    eval_response = client.files.create(file=file, purpose=\"evals\")\n",
    "\n",
    "eval_file_id = eval_response.id\n",
    "\n",
    "print(\"Evaluation file ID:\", eval_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefc7af",
   "metadata": {},
   "source": [
    "### Prepare Prompt for Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "93ab0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Don't make assumptions about what values to plug into functions. If you can't find the exact stock ticker symbol, you can ask for clarification. \"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_current_stock_price\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {},\n",
    "          \"required\": [\n",
    "            \"symbol\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"get_last_nday_stock_price\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {},\n",
    "          \"required\": [\n",
    "            \"symbol\",\n",
    "            \"period\"\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6111",
   "metadata": {},
   "source": [
    "### Define python grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a846425",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_grader = \"\"\"\n",
    "def grade(sample, item) -> float:\n",
    "    actual_tool_calls = sample['output_tools']\n",
    "    expected_tool_calls = item['expected_tool_calls']\n",
    "    return grade_tool_calls(actual_tool_calls, expected_tool_calls)\n",
    "\n",
    "def grade_tool_calls(actual_tool_calls, expected_tool_calls):\n",
    "    # Case 1: Both are empty (None or empty list)\n",
    "    if (not actual_tool_calls) and (not expected_tool_calls):\n",
    "        return 1.0\n",
    "\n",
    "    # Case 2: One is empty, one is not\n",
    "    if (not actual_tool_calls) != (not expected_tool_calls):\n",
    "        return 0.0\n",
    "\n",
    "    # Case 3: Both are not empty - check if function objects are equal\n",
    "    if actual_tool_calls and expected_tool_calls:\n",
    "        return compare_function_calls(actual_tool_calls, expected_tool_calls)\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def compare_function_calls(actual_calls, expected_calls):\n",
    "    if len(actual_calls) != len(expected_calls):\n",
    "        return 0.11\n",
    "\n",
    "    for actual, expected in zip(actual_calls, expected_calls):\n",
    "        # Compare function name and arguments, ignore call ID\n",
    "        actual_func = actual.get(\"function\", {})\n",
    "        expected_func = expected.get(\"function\", {})\n",
    "\n",
    "        # Compare function name\n",
    "        if actual_func.get(\"name\") != expected_func.get(\"name\"):\n",
    "            return 0.12\n",
    "\n",
    "        # Compare function arguments (parse JSON strings if needed)\n",
    "        actual_args = actual_func.get(\"arguments\", \"{}\")\n",
    "        expected_args = expected_func.get(\"arguments\", \"{}\")\n",
    "\n",
    "        try:\n",
    "            actual_args_dict = json.loads(actual_args) if isinstance(actual_args, str) else actual_args\n",
    "            expected_args_dict = json.loads(expected_args) if isinstance(expected_args, str) else expected_args\n",
    "\n",
    "            if actual_args_dict != expected_args_dict:\n",
    "                return 0.13\n",
    "        except json.JSONDecodeError:\n",
    "            # If we can't parse, do string comparison\n",
    "            if actual_args != expected_args:\n",
    "                return 0.14\n",
    "\n",
    "    return 1.0\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d5344",
   "metadata": {},
   "source": [
    "### Create Stock Hallucination Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8837c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_eval = client.evals.create(\n",
    "    name=\"Stock Hallucination Eval\",\n",
    "    data_source_config={\n",
    "        \"type\": \"custom\",\n",
    "        \"item_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\"},\n",
    "                \"expected_tool_calls\": {\"type\": \"array\"},\n",
    "            },\n",
    "            \"required\": [\"query\", \"expected_tool_calls\"],\n",
    "        },\n",
    "        \"include_sample_schema\": True,\n",
    "    },\n",
    "    testing_criteria=[\n",
    "        {\n",
    "            \"type\": \"python\",\n",
    "            \"name\": \"Tool Use Evaluator\",\n",
    "            \"source\": python_grader,\n",
    "            \"pass_threshold\": 0.5,\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881aefb2",
   "metadata": {},
   "source": [
    "### Define data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "83f7a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_template = {\n",
    "    \"type\": \"completions\",\n",
    "    \"source\": {\"type\": \"file_id\", \"id\": eval_file_id},\n",
    "    \"input_messages\": {\n",
    "        \"type\": \"template\",\n",
    "        \"template\": [\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"system\",\n",
    "                \"content\": {\"type\": \"input_text\", \"text\": system_prompt},\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": {\"type\": \"input_text\", \"text\": \"{{item.query}}\"},\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    \"sampling_params\": {\n",
    "        \"temperature\": 0.0,\n",
    "        \"tools\": tools,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f084d",
   "metadata": {},
   "source": [
    "### Create sampling runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef52fbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Unknown parameter: 'data_source.sampling_params.tools'.\", 'type': 'invalid_request_error', 'param': 'data_source.sampling_params.tools', 'code': 'unknown_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gpt_41_completions_run = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstock_eval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata_source_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m gpt_41_mini_completions_run = client.evals.runs.create(\n\u001b[32m      7\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     eval_id=stock_eval.id,\n\u001b[32m      9\u001b[39m     data_source={**data_source_template, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-mini\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# gpt_41_mini_ft_completions_run = client.evals.runs.create(\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#     name=model_deployment_name,\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#     eval_id=stock_eval.id,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#     data_source={**data_source_template, \"model\": model_deployment_name},\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/resources/evals/runs/runs.py:102\u001b[39m, in \u001b[36mRuns.create\u001b[39m\u001b[34m(self, eval_id, data_source, metadata, name, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m eval_id:\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `eval_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/evals/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43meval_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/runs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_source\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRunCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunCreateResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Unknown parameter: 'data_source.sampling_params.tools'.\", 'type': 'invalid_request_error', 'param': 'data_source.sampling_params.tools', 'code': 'unknown_parameter'}}"
     ]
    }
   ],
   "source": [
    "gpt_41_completions_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1\",\n",
    "    eval_id=stock_eval.id,\n",
    "    data_source={**data_source_template, \"model\": \"gpt-4.1\"},\n",
    ")\n",
    "gpt_41_mini_completions_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1-mini\",\n",
    "    eval_id=stock_eval.id,\n",
    "    data_source={**data_source_template, \"model\": \"gpt-4.1-mini\"},\n",
    ")\n",
    "gpt_41_mini_ft_completions_run = client.evals.runs.create(\n",
    "    name=fine_tuned_model,\n",
    "    eval_id=stock_eval.id,\n",
    "    data_source={**data_source_template, \"model\": fine_tuned_model},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db3087",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'Run evalrun_68acf4faa5488191a77a3dea38abaa0f cannot be found. Please confirm the run_id or permissions to view it.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      9\u001b[39m         time.sleep(\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mpoll_runs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstock_eval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgpt_41_completions_run\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgpt_41_mini_completions_run\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# gpt_41_mini_ft_completions_run.id,\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mpoll_runs\u001b[39m\u001b[34m(eval_id, run_ids)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpoll_runs\u001b[39m(eval_id, run_ids):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# poll both runs at the same time, until they are complete or failed\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         runs = [\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m run_id \u001b[38;5;129;01min\u001b[39;00m run_ids]\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m runs:\n\u001b[32m      6\u001b[39m             \u001b[38;5;28mprint\u001b[39m(run.id, run.status, run.result_counts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/resources/evals/runs/runs.py:146\u001b[39m, in \u001b[36mRuns.retrieve\u001b[39m\u001b[34m(self, run_id, eval_id, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_id:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `run_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/evals/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43meval_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/runs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunRetrieveResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1195\u001b[39m, in \u001b[36mSyncAPIClient.get\u001b[39m\u001b[34m(self, path, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1192\u001b[39m opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m, url=path, **options)\n\u001b[32m   1193\u001b[39m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[32m   1194\u001b[39m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/azureai-samples/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'Run evalrun_68acf4faa5488191a77a3dea38abaa0f cannot be found. Please confirm the run_id or permissions to view it.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "def poll_runs(eval_id, run_ids) -> None:\n",
    "    # poll both runs at the same time, until they are complete or failed\n",
    "    while True:\n",
    "        runs = [client.evals.runs.retrieve(run_id, eval_id=eval_id) for run_id in run_ids]\n",
    "        for run in runs:\n",
    "            print(run.id, run.status, run.result_counts)\n",
    "        if all(run.status in (\"completed\", \"failed\") for run in runs):\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "poll_runs(\n",
    "    stock_eval.id,\n",
    "    [\n",
    "        gpt_41_completions_run.id,\n",
    "        gpt_41_mini_completions_run.id,\n",
    "        gpt_41_mini_ft_completions_run.id,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701f599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
